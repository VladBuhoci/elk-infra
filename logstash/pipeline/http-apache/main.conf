input {
  http {
    id => "http-apache-input"
    port => 1701

    codec => multiline {
      pattern => "^(\s+|\t)|(Caused by:)"
      what => "previous"
      auto_flush_interval => 5
    }
  }
}

filter {
  if [url][path] =~ "error" {
    mutate {
      replace => {
        "type" => "error"
      }
    }
  }
  else if "multiline" in [tags] {
    mutate {
      replace => {
        "type" => "error"
      }
    }

    prune {
      whitelist_names => ["^type$", "^message$", "@version", "@timestamp"]
    }

    grok {
      match => {
        # Match the components of the first line in the error log message (so we ignore the stacktrace).
        "message" => "%{CATALINA_DATESTAMP:[@metadata][timestamp]} %{LOGLEVEL:level} %{JAVACLASS:class}: (?<msg>.+?(?=(\n|\r|\r\n)))"
      }
    }

    # Check if grok pattern matching failed earlier...
    if "_grokparsefailure" in [tags] {
      # Silently drop the current event...
      drop {
      }
    }

    mutate {
      remove_field => ["message"]
    }

    # Set the timestamp of the Logstash event based on the timestamp from the received log line (Tomcat's log format).
    date {
      match => ["[@metadata][timestamp]", "MMM dd, yyyy KK:mm:ss aa"]
    }
  }
  else {
    mutate {
      replace => {
        "type" => "access"
      }
    }

    prune {
      whitelist_names => ["^type$", "^message$", "@version", "@timestamp"]
    }

    grok {
      match => {
        # "message" => "%{IP:ip_address} %{USER:identity} %{USER:auth} \[%{HTTPDATE:req_timestamp}\] \"%{WORD:http_method} %{URIPATHPARAM:http_path} HTTP/%{NUMBER:http_version}\" %{INT:http_status:int} %{INT:payload_size_bytes:int} %{QS:referrer} %{QS:http_user_agent}"
        # ..
        # This one combines everything enumerated above:
        "message" => "%{HTTPD_COMBINEDLOG}"
      }
    }

    # Check if grok pattern matching failed earlier...
    if "_grokparsefailure" in [tags] {
      # Silently drop the current event...
      drop {
      }
    }

    # Get the browser/client used by the input provider.
    useragent {
      source => "[user_agent][original]"
      target => "[user_agent]"
    }

    # Admin pages.
    if [url][path] =~ /^\/admin\// {
      drop {
      }
    }

    # Static files.
    if [url][path] =~ /^\/js\// or [url][path] =~ /^\/css\// or [url][path] in ["/robots.txt", "/favicon.ico"] {
      drop {
      }
    }

    # Check for web crawlers (makes use of newly populated user_agent' fields).
    if [user_agent][device][name] == "Spider" {
      drop {
      }
    }

    mutate {
      remove_field => ["message"]
    }

    # Set the timestamp of the Logstash event based on the timestamp from the received log line (Apache server's log format).
    date {
      match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
      remove_field => ["timestamp"]
    }

    # Enrich the current event with geographical information, based on the IP address found in the matched input payload.
    geoip {
      source => "[source][address]"
      target => "client_geo"
    }
  }
}

output {
  elasticsearch {
    id => "http-apache-elastic-output"
    hosts => ["https://elastic-01", "https://elastic-02", "https://elastic-03"]
    ssl_certificate_authorities => ["/usr/share/logstash/config/certs/ca/ca.crt"]
    compression_level => 4      # values range from 0 (off) to 9 (best compression results and lowest network bandwidth, but CPU usage increases).
    user => "logstash_internal" # user account created by "init_logstash_creds.sh" script.
    password => "lopass"        # user account created by "init_logstash_creds.sh" script.
    index => "mylogs-%{type}-%{+YYYY.MM.dd}"  # index pattern privileges for current user set by "init_logstash_creds.sh" script.
  }

  stdout {
    id => "http-apache-std-output"
    codec => rubydebug {
      metadata => true  # Display metadata fields too.
    }
  }
}
